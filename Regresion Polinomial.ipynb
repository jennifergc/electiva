{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style = 'color:green'> Descubriendo la cinemática con Machine Learning\n",
    "Veamos un ejemplo bastante simple: la <span style = 'color:#eb3433'> fuerza de gravedad </span> sobre un objeto en caída. La ecuación que define el <span style = 'color:#eb3433'> movimiento de esta partícula </span> es:\n",
    "    $$y = x_{0} + v_{0}t - \\frac{1}{2} gt$$\n",
    "    \n",
    "**Creación del set de datos**\n",
    "\n",
    "Creamos una función en Python para calcular esta posición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import math\n",
    "random.seed\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#\\usepackage[shortconst]{physconst}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def location(x_0, v_0, t):\n",
    "    return x_0 + v_0*t - (9.82/2)*t**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo un dataset para guardarlo como un archivo CSV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gravity_location_data.csv', mode='w') as gravity_file:\n",
    "    gravity_writer = csv.writer(gravity_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    gravity_writer.writerow(['initial_position', 'initial_velocity', 'mass', 'time', 'location'])\n",
    "    \n",
    "    for i in range (0, 10000):\n",
    "        initial_position = random.randrange(1, 10000)\n",
    "        initial_velocity = random.randrange(1, 100)\n",
    "        mass = random.randrange(1, 1000)\n",
    "        time = random.randrange(1, 100)\n",
    "        gravity_writer.writerow([initial_position, initial_velocity, mass, time, location(initial_position, initial_velocity, time)])\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿por qué <span style = 'color:#eb3433'> incluir la masa </span> en este conjunto de datos? Porque queremos intentar engañar al algoritmo de aprendizaje de la máquina para que lo use.\n",
    "\n",
    "Importemos el nuevo archivo de datos..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gravity_data = pd.read_csv('gravity_location_data.csv')\n",
    "df_location = pd.DataFrame(gravity_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como es habitual en el aprendizaje automático, necesitaremos dividir nuestros datos en un <span style = 'color:#eb3433'> conjunto de entrenamiento </span>  (para entrenar el modelo) y un <span style = 'color:#eb3433'> conjunto de pruebas </span> (para evaluar el modelo entrenado). Para ellos se usa una función especial para Python: sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def split_data(data, target_name):\n",
    "    y = data[target_name]\n",
    "    X = data.drop(target_name, axis=1)\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entrenar y evaluar nuestro modelo, usaremos la siguiente función:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from math import sqrt\n",
    "def train_eval_poly(X_train, X_test, y_train, y_test):\n",
    "    regression_model = LinearRegression() \n",
    "    \n",
    "    poly = PolynomialFeatures(degree=2)\n",
    "    X_train_transform = poly.fit_transform(X_train)\n",
    "    X_test_transform = poly.fit_transform(X_test)\n",
    "    \n",
    "    regression_model.fit(X_train_transform, y_train)\n",
    "    \n",
    "    print(poly.fit(X_train).get_feature_names(X_train.columns))\n",
    "    \n",
    "    y_pred = regression_model.predict(X_test_transform)\n",
    "    print(\"R2: \\t\", r2_score(y_test, y_pred))\n",
    "    print(\"RMSE: \\t\", sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    print(\"MAE: \\t\", mean_absolute_error(y_test, y_pred))\n",
    "    \n",
    "    return regression_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nótese que esto es sólo una Regresión Lineal, excepto que usamos la función los Polinomios Característicos para transformar los datos de manera que la Regresión Lineal pueda modelar correctamente un polinomio de segundo grado, lo cual sabemos que en este caso es exactamente lo que estamos buscando. A continuación veremos un poco más sobre cómo se transforman los datos.\n",
    "\n",
    "Después de entrenar el modelo, obtendremos los nombres de las características, que nos dirán cómo se asignan los coeficientes resultantes.\n",
    "Ahora entrenamos el modelo con este código:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', 'initial_position', 'initial_velocity', 'mass', 'time', 'initial_position^2', 'initial_position initial_velocity', 'initial_position mass', 'initial_position time', 'initial_velocity^2', 'initial_velocity mass', 'initial_velocity time', 'mass^2', 'mass time', 'time^2']\n",
      "R2: \t 1.0\n",
      "RMSE: \t 2.522726153057001e-09\n",
      "MAE: \t 2.1540236041506234e-09\n"
     ]
    }
   ],
   "source": [
    "df_split = split_data(df_location, 'location')\n",
    "lrModel = train_eval_poly(*df_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenga en cuenta que el valor de r² es 1.0 -  Además, la raíz media del error cuadrado (RMSE) y la media del error absoluto (MAE) son minúsculas - el e-09 significa multiplicar el número precedente por .000000001. Así que la raíz media del error al cuadrado es en realidad 0,00000000285... A esta escala eso es minúsculo, esencialmente cero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe también la lista inicial de 15 elementos en los resultados anteriores. Este es el resultado del método PolynomialFeatures. Transformó el conjunto inicial de cuatro características ('posición_inicial', 'velocidad_inicial', 'masa', 'tiempo') y las cambió en combinaciones de estas características, como 'posición_inicial ^ 2' y 'tiempo_de_posición_inicial', cuyos valores son posición_inicial multiplicada por el tiempo. Este conjunto expandido de características fue entonces alimentado en la simple y vieja Regresión Lineal. Este es un pequeño truco que nos permite realizar la regresión polinómica no con un algoritmo diferente sino con datos transformados.\n",
    "Ahora veamos los exponentes de nuestro modelo, que son los exponentes de la ecuación polinómica que el modelo está usando para hacer predicciones:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00,  1.00000000e+00, -5.09744168e-13, -1.07288336e-13,\n",
       "       -3.41389880e-13, -1.11022302e-16,  2.58256957e-16,  1.66533454e-16,\n",
       "       -5.86336535e-16,  7.30679081e-15, -1.05232663e-15,  1.00000000e+00,\n",
       "       -5.72675588e-16, -1.47803861e-15, -4.91000000e+00])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrModel.coef_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer valor (0.00000000e+00, o 0) es el coeficiente para el valor 1. Eso sería una constante colgante sin ninguna variable, un valor constante siempre añadido a la ecuación, excepto que el coeficiente es cero por lo que no hay un valor constante añadido a nuestro resultado. El segundo valor de nuestra matriz ( 1.00000000e+00, o 1) es el coeficiente en \"posición_inicial\". Y de hecho, en nuestra ecuación original, tenemos la posición inicial (X₀) con un coeficiente de uno.\n",
    "\n",
    "La mayoría de nuestros otros coeficientes son esencialmente cero, y nos dicen que estos factores son irrelevantes para predecir la ubicación, pero tenemos algunos que no lo son. El duodécimo de nuestra lista es también un coeficiente de 1, que corresponde al \"tiempo_de_velocidad_inicial\", o velocidad inicial multiplicada por el tiempo. De nuevo, tenemos este factor en nuestra ecuación original, que aparece como V₀*t.\n",
    "Finalmente, el último valor es -4.9, que es el coeficiente correspondiente al 'tiempo ^ 2'. Note que esto también aparece en nuestra ecuación original como -1/2 gt². Pero dijimos antes que g es aproximadamente 9,8, y -1/2 * 9,8 = -4,9. Así que esto también se corresponde con nuestra ecuación original.\n",
    "\n",
    "Si se comparan estos coeficientes con las combinaciones de variables de la lista de nombres de características, y se suman, e ignoran los casos en que el coeficiente es esencialmente cero, se terminaría con una ecuación muy cercana a la inicial.\n",
    "\n",
    "Hay dos puntos finales muy interesantes para hacer aquí. Primero, el modelo resultante encontró que la masa era irrelevante para hacer la predicción, lo cual es correcto.\n",
    "\n",
    "Segundo, el algoritmo de aprendizaje de la máquina fue capaz de derivar la constante de aceleración gravitatoria g, o al menos determinar el valor de todo el coeficiente (-1/2 * 9,8) que incluye g.\n",
    "\n",
    "En otras palabras, parte del trabajo de Isaac Newton y Galileo puede ser descubierto en segundos con Python y scikit-learn. Esto es bastante emocionante.\n",
    "\n",
    "Por supuesto, el análisis y la comprensión de estos resultados todavía requiere una importante intervención humana, pero esto al menos nos da una idea de cómo se puede extraer de los datos la comprensión de las leyes fundamentales del universo.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
